{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import string\n",
    "import requests\n",
    "import numpy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_and_clean_data():\n",
    "    data = pd.read_csv('data/software_developer_united_states_1971_20191023_1.csv')\n",
    "    description = data['job_description']\n",
    "    cleaned_description = description.apply(lambda s: s.translate(str.maketrans('','',\n",
    "                                                                                string.punctuation + u'\\xa0')))\n",
    "    cleaned_description = cleaned_description.apply(lambda s: s.lower())\n",
    "    cleaned_description = cleaned_description.apply(\n",
    "        lambda s: s.translate(\n",
    "            str.maketrans(string.whitespace, ' ' * len(string.whitespace), '')))\n",
    "    cleaned_description = cleaned_description.drop_duplicates()\n",
    "    return cleaned_description\n",
    "\n",
    "\n",
    "def simple_tokenize(data):\n",
    "    clean_description = data.apply(lambda s: [x.strip() for x in s.split()])\n",
    "    return clean_description\n",
    "\n",
    "\n",
    "def parse_job_description():\n",
    "    clean_description = get_and_clean_data()\n",
    "    clean_description = simple_tokenize(clean_description)\n",
    "    return clean_description\n",
    "\n",
    "\n",
    "def count_java():\n",
    "    parse_description = parse_job_description()\n",
    "    count_java = parse_description.apply(lambda s: 'java' in s).sum()\n",
    "    print('java: ' + str(count_java) + ' of ' + str(\n",
    "        parse_description.shape[0]))\n",
    "\n",
    "\n",
    "def parse_db():\n",
    "    html_doc = requests.get(\"https://db-engines.com/en/ranking\").content\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    db_table = soup.find(\"table\", {\"class\": \"dbi\"})  # find the table that class=\"dbi\"\n",
    "    all_db = [''.join(s.find('a').findAll(string=True, recursive=False)).strip() for s in\n",
    "              db_table.findAll(\"th\", {\n",
    "                  \"class\": \"pad-l\"})]  # find all the hypertext references that is a string without recursive then strip them in the <th> with class=\"pad-l\"\n",
    "    all_db = list(dict.fromkeys(all_db))  # search fromkeys\n",
    "    db_list = all_db[:10]  # get top 10\n",
    "    db_list = [s.lower() for s in db_list]  # lower case all texts\n",
    "    db_list = [[x.strip() for x in s.split()] for s in\n",
    "               db_list]  # split into the word then remove the leading and trailing whitespaces\n",
    "    return db_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count_java()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
